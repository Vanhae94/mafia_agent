"""
LangGraph Nodes
ê° ê¸°ëŠ¥ì„ Nodeë¡œ ì •ì˜
"""

from typing import Dict, Any, List
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langgraph.types import interrupt
import os
from dotenv import load_dotenv
import random
import json

load_dotenv()


def setup_game_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê²Œì„ ì´ˆê¸° ì„¸íŒ… ë…¸ë“œ
    - ìºë¦­í„° ì •ë³´ ë¡œë“œ
    - ë¬´ì‘ìœ„ ë²”ì¸ ì„ ì •
    """
    from characters import student, office_worker, artist, chef, teacher

    character_modules = [student, office_worker, artist, chef, teacher]

    # ìºë¦­í„° ì •ë³´ ìˆ˜ì§‘
    characters = []
    for module in character_modules:
        char_info = module.get_character_info()
        characters.append(char_info)

    # ë¬´ì‘ìœ„ ë²”ì¸ ì„ ì •
    phantom = random.choice(characters)

    # ì´ˆê¸° ìƒì¡´ ìƒíƒœ ë° ì˜ì‹¬ ì¹´ìš´íŠ¸ ì„¤ì •
    alive_status = {char["name"]: True for char in characters}
    suspicion_counts = {char["name"]: 0 for char in characters}

    return {
        "characters": characters,
        "phantom_name": phantom["name"],
        "round_number": 1,
        "phase": "discussion",
        "day_night": "day",
        "turn_count": 0,
        "messages": [SystemMessage(content="ğŸ‘» íŒ¬í…€ ë¡œê·¸ ì‹œì‘! ì°¸ê°€ì 5ëª… ì¤‘ 1ëª…ì´ ì¸ê°„ìœ¼ë¡œ ë‘”ê°‘í•œ ìœ ë ¹ 'íŒ¬í…€'ì…ë‹ˆë‹¤. ë°¤ë§ˆë‹¤ íŒ¬í…€ì€ í•œ ëª…ì”© ì œê±°í•©ë‹ˆë‹¤. íŒ¬í…€ì„ ì°¾ì•„ë‚´ì§€ ëª»í•˜ë©´ ëª¨ë‘ê°€ ìœ„í—˜í•©ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° ì„œë¡œë¥¼ ê´€ì°°í•˜ê³ , ëŒ€í™”í•˜ë©°, ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í–‰ë™ì„ ì°¾ì•„ë‚´ì„¸ìš”.")],
        "votes": {},
        "current_speaker": characters[0]["name"],
        "next_speaker": None,
        "user_input": None,
        "user_target": None,
        "accused": None,
        "game_result": None,
        "alive_status": alive_status,
        "suspicion_counts": suspicion_counts,
        "night_logs": [],
        "clues": [],
        "round_summary": "",
        "round_summaries": {},
        "death_log": []
    }


def night_phase_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë°¤ í˜ì´ì¦ˆ ì²˜ë¦¬ ë…¸ë“œ
    - ë¼ìš´ë“œ ì¦ê°€
    - í¬ìƒì ì„ ì • (íŒ¬í…€ ì œì™¸, ìƒì¡´ì ì¤‘ ëœë¤)
    - ìƒì¡´ ìƒíƒœ ì—…ë°ì´íŠ¸
    - ë°¤ í–‰ë™ ë¡œê·¸ ìƒì„±
    """
    characters = state.get("characters", [])
    phantom_name = state.get("phantom_name")
    alive_status = state.get("alive_status", {})
    round_number = state.get("round_number", 1)
    
    # ìƒì¡´ì ëª©ë¡ (íŒ¬í…€ ì œì™¸)
    targets = [
        char for char in characters 
        if char["name"] != phantom_name and alive_status.get(char["name"], True)
    ]
    
    night_log_entry = ""
    victim_name = None
    
    if targets:
        # í¬ìƒì ì„ ì •
        victim = random.choice(targets)
        victim_name = victim["name"]
        
        # ì‚¬ë§ ì²˜ë¦¬
        alive_status[victim_name] = False
        
        # ë¡œê·¸ ìƒì„±
        night_log_entry = f"Round {round_number} Night: {victim_name}ì´(ê°€) ìŠµê²©ë‹¹í•´ ì‚¬ë§í–ˆìŠµë‹ˆë‹¤."
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        message = f"ğŸŒ™ ë°¤ì´ ì§€ë‚¬ìŠµë‹ˆë‹¤.\nì•ˆíƒ€ê¹ê²Œë„ {victim_name}ì´(ê°€) ì‚´í•´ë‹¹í•œ ì±„ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        
        # --- ë‹¨ì„œ ìƒì„± ë¡œì§ (LLM) ---
        try:
            # íŒ¬í…€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            phantom_char = next((c for c in characters if c["name"] == phantom_name), None)
            
            if phantom_char:
                llm = ChatGoogleGenerativeAI(
                    model="gemini-2.0-flash",
                    google_api_key=os.getenv("GOOGLE_API_KEY")
                )
                
                clue_prompt = f"""
ë‹¹ì‹ ì€ ì¶”ë¦¬ ì†Œì„¤ì˜ ì‘ê°€ì…ë‹ˆë‹¤.
'íŒ¬í…€ ë¡œê·¸'ë¼ëŠ” ê²Œì„ì—ì„œ ë°¤ì‚¬ì´ ì‚´ì¸ ì‚¬ê±´ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
íŒ¬í…€(ë²”ì¸)ì˜ íŠ¹ì§•ì„ ì•”ì‹œí•˜ëŠ” 'í˜„ì¥ ì¦ê±°(ë‹¨ì„œ)'ë¥¼ í•˜ë‚˜ ìƒì„±í•´ì£¼ì„¸ìš”.

[íŒ¬í…€ ì •ë³´]
- ì´ë¦„: {phantom_char['name']}
- ì§ì—…: {phantom_char['job']}
- ì„±ê²©: {phantom_char['personality']}
- íŠ¹ì§•: {phantom_char.get('prompt', '')[:200]}...

[í”¼í•´ì ì •ë³´]
- ì´ë¦„: {victim_name}

[ìš”ì²­ì‚¬í•­]
1. íŒ¬í…€ì˜ ì§ì—…ì´ë‚˜ ì„±ê²©, ì·¨ë¯¸ì™€ ê´€ë ¨ëœ ë¯¸ë¬˜í•œ ë‹¨ì„œë¥¼ ë§Œë“œì„¸ìš”.
2. **ì ˆëŒ€ íŒ¬í…€ì˜ ì´ë¦„ì„ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.**
3. **ì§ì—…ëª…ì„ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.** (ì˜ˆ: "ë¶“" ëŒ€ì‹  "ë¬¼ê° ëƒ„ìƒˆ", "ìš”ë¦¬ì‚¬ ëª¨ì" ëŒ€ì‹  "íŠ¹ì´í•œ í–¥ì‹ ë£Œ")
4. ëƒ„ìƒˆ, ì†Œë¦¬, ë–¨ì–´ì§„ ë¬¼ê±´, í”ì  ë“± ê°ê°ì ì¸ ë¬˜ì‚¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
5. í•œ ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”.

ì˜ˆì‹œ:
- (í™”ê°€ê°€ ë²”ì¸ì¼ ë•Œ): "í”¼í•´ìì˜ ì˜·ê¹ƒì—ì„œ í¬ë¯¸í•˜ê²Œ í…Œë ˆë¹ˆìœ  ëƒ„ìƒˆê°€ ë‚œë‹¤."
- (í•™ìƒì´ ë²”ì¸ì¼ ë•Œ): "í˜„ì¥ì— ì°¢ì–´ì§„ ì „ê³µ ì„œì ì˜ í•œ í˜ì´ì§€ê°€ ë–¨ì–´ì ¸ ìˆë‹¤."
"""
                response = llm.invoke([HumanMessage(content=clue_prompt)])
                clue_text = response.content.strip()
                
                # ë‹¨ì„œ ì €ì¥
                clues = state.get("clues", [])
                clues.append(f"[Day {round_number+1} ì•„ì¹¨ ë°œê²¬] {clue_text}")
                state["clues"] = clues
                
        except Exception as e:
            print(f"Clue Generation Error: {e}")

    else:
        message = "ğŸŒ™ ë°¤ì´ ì§€ë‚¬ìŠµë‹ˆë‹¤. ì•„ë¬´ ì¼ë„ ì¼ì–´ë‚˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    return {
        "round_number": round_number + 1,
        "phase": "discussion", # ë‹¤ì‹œ ë‚® í† ë¡ ìœ¼ë¡œ
        "day_night": "day",
        "alive_status": alive_status,
        "night_logs": [night_log_entry] if night_log_entry else [],
        "clues": state.get("clues", []),
        "messages": [SystemMessage(content=message)],
        "turn_count": 0
    }


def character_speak_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ìºë¦­í„°ê°€ ë§í•˜ëŠ” ë…¸ë“œ
    current_speakerì— í•´ë‹¹í•˜ëŠ” ìºë¦­í„°ê°€ ë°œì–¸
    """
    speaker_name = state.get("current_speaker")

    if not speaker_name:
        return state

    # í•´ë‹¹ ìºë¦­í„° ì°¾ê¸°
    character = None
    for char in state["characters"]:
        if char["name"] == speaker_name:
            character = char
            break

    if not character:
        return state

    # LLM ì´ˆê¸°í™”
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = character["prompt"]

    # ì˜ì‹¬ ìˆ˜ì¹˜ ë°˜ì˜
    suspicion_counts = state.get("suspicion_counts", {})
    my_suspicion = suspicion_counts.get(speaker_name, 0)
    
    # ë¼ìš´ë“œ ìš”ì•½ ë°˜ì˜ (ê¸°ì–µ)
    round_summaries = state.get("round_summaries", {})
    if round_summaries:
        summary_text = "\n".join([f"[Round {r} ìš”ì•½]: {s}" for r, s in round_summaries.items()])
        system_prompt += f"\n\n[ì§€ë‚œ ë¼ìš´ë“œ ê¸°ì–µ]\n{summary_text}\n"
    
    system_prompt += f"\n\n[ìƒíƒœ ì •ë³´]\ní˜„ì¬ ë‹¹ì‹ ì˜ ì˜ì‹¬ ìˆ˜ì¹˜: {my_suspicion}\n"
    
    # ì˜ì‹¬ ìˆ˜ì¹˜ë³„ ê°ì •ì„  ë‹¨ê³„í™”
    if 1 <= my_suspicion <= 2:
        system_prompt += """
[ì‹¬ë¦¬ ìƒíƒœ: ì•½ê°„ì˜ ì‹ ê²½ ì“°ì„]
ëˆ„êµ°ê°€ ë‚˜ë¥¼ ì˜ì‹¬í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì¸ì§€í–ˆìŠµë‹ˆë‹¤.
- í‰ì†Œë³´ë‹¤ ì¡°ê¸ˆ ë” ì‹ ì¤‘í•˜ê²Œ ë§í•˜ì„¸ìš”.
- "ì €ë¥¼ ì˜ì‹¬í•˜ì‹œëŠ” ê±´ê°€ìš”?" ì •ë„ë¡œ ê°€ë³ê²Œ ë°˜ì‘í•˜ê±°ë‚˜, ìƒí™©ì„ ì‚´í”¼ì„¸ìš”.
"""
    elif 3 <= my_suspicion <= 4:
        system_prompt += """
[ì‹¬ë¦¬ ìƒíƒœ: ë¶ˆì¾Œí•¨ ë° ë°©ì–´ì ]
ì˜ì‹¬ì´ ì»¤ì§€ê³  ìˆì–´ ê¸°ë¶„ì´ ë‚˜ì˜ê³  ê¸´ì¥ë©ë‹ˆë‹¤.
- ë‹¤ì†Œ ë‚ ì¹´ë¡­ê±°ë‚˜ ë°©ì–´ì ì¸ íƒœë„ë¥¼ ë³´ì´ì„¸ìš”.
- "ì™œ ìê¾¸ ì €ë¥¼ ëª°ì•„ê°€ì‹œì£ ?", "ê·¼ê±° ì—†ëŠ” ì˜ì‹¬ì€ í•˜ì§€ ë§ˆì„¸ìš”."ë¼ë©° ë¶ˆì¾Œí•´í•˜ì„¸ìš”.
"""
    elif my_suspicion >= 5:
        system_prompt += """
[ì‹¬ë¦¬ ìƒíƒœ: ê·¹ë„ì˜ ë¶ˆì•ˆ ë° íŒ¨ë‹‰]
ì‚¬ëŒë“¤ì´ ë‚˜ë¥¼ íŒ¬í…€ìœ¼ë¡œ í™•ì‹ í•˜ëŠ” ê²ƒ ê°™ì•„ ë§¤ìš° ë¶ˆì•ˆí•©ë‹ˆë‹¤.
- ëª©ì†Œë¦¬ê°€ ë–¨ë¦¬ê±°ë‚˜, ê°ì •ì ìœ¼ë¡œ ê²©í•´ì§€ì„¸ìš”.
- ì–µìš¸í•¨ì„ í˜¸ì†Œí•˜ê±°ë‚˜, ê°•í•˜ê²Œ í™”ë¥¼ ë‚´ë©° ìƒí™©ì„ ëª¨ë©´í•˜ë ¤ í•˜ì„¸ìš”.
"""

    # ë²”ì¸ì´ë¼ë©´ íŠ¹ë³„ ì§€ì‹œ ì¶”ê°€
    if character["name"] == state["phantom_name"]:
        system_prompt += """

=== ì¤‘ìš”: ë‹¹ì‹ ì˜ ì—­í•  ===
ğŸ”´ ë‹¹ì‹ ì€ ì´ë²ˆ ê²Œì„ì˜ **íŒ¬í…€(ì‚´ì¸ë§ˆ)**ì…ë‹ˆë‹¤.

íŒ¬í…€ìœ¼ë¡œì„œì˜ ì„ë¬´:
1. ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ë“¤í‚¤ì§€ ì•Šê¸°
2. í‰ì†Œ ì„±ê²©ëŒ€ë¡œ í–‰ë™í•˜ë˜, ì˜ì‹¬ë°›ì§€ ì•Šë„ë¡ ì¡°ì‹¬
3. í•„ìš”í•˜ë©´ ê±°ì§“ ì•Œë¦¬ë°”ì´ë¥¼ ë§Œë“¤ì–´ë‚´ê¸°
4. ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë¥¸ ì‚¬ëŒì„ ì˜ì‹¬í•˜ê¸°
========================
"""
        # íŒ¬í…€ ì „ìš© ë°˜ì‘ (ì˜ì‹¬ ìˆ˜ì¹˜ 3 ì´ìƒë¶€í„°)
        if my_suspicion >= 3:
            system_prompt += """
ğŸš¨ [ìœ„ê¸° ìƒí™©] ì˜ì‹¬ ìˆ˜ì¹˜ê°€ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤! (3 ì´ìƒ)
ë‹¹ì‹ ì€ ì •ì²´ê°€ ë“¤í‚¬ê¹Œ ë´ ë§¤ìš° ë‹¹í™©í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- ë§ì´ ë¹¨ë¼ì§€ê±°ë‚˜, íš¡ì„¤ìˆ˜ì„¤í•˜ê±°ë‚˜, ì•ë’¤ê°€ ì•ˆ ë§ëŠ” ë§ì„ í•˜ì„¸ìš”.
- "ì•„ë‹ˆ, ê·¸ê²Œ ì•„ë‹ˆë¼...", "ì ê¹ë§Œìš”, ì œ ë§ ì¢€ ë“¤ì–´ë³´ì„¸ìš”!" ê°™ì€ í‘œí˜„ì„ ì“°ë©° í•„ì‚¬ì ìœ¼ë¡œ ë³€ëª…í•˜ì„¸ìš”.
- ë§ì‹¤ìˆ˜ë¥¼ í•˜ê±°ë‚˜ ê³¼ë„í•˜ê²Œ í™”ë¥¼ ë‚´ëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤.
"""
    else:
        # ì‹œë¯¼ì¸ë° ì˜ì‹¬ë°›ëŠ” ê²½ìš° (5 ì´ìƒì¼ ë•Œ ë” ê°•ë ¥í•œ ë°˜ì‘)
        if my_suspicion >= 5:
            system_prompt += """
ğŸš¨ [ìœ„ê¸° ìƒí™©] ì–µìš¸í•˜ê²Œ íŒ¬í…€ìœ¼ë¡œ ëª°ë¦¬ê³  ìˆìŠµë‹ˆë‹¤! (ì˜ì‹¬ ìˆ˜ì¹˜ 5 ì´ìƒ)
ë‹¹ì‹ ì€ ê²°ë°±í•œë° ì•„ë¬´ë„ ë¯¿ì–´ì£¼ì§€ ì•Šì•„ ë‹µë‹µí•´ ë¯¸ì¹  ì§€ê²½ì…ë‹ˆë‹¤.
- "ì§„ì§œ ì•„ë‹ˆë¼ë‹ˆê¹Œìš”!!", "ì¦ê±°ë¥¼ ëŒ€ë³´ì„¸ìš”!"ë¼ë©° ì†Œë¦¬ì¹˜ê±°ë‚˜ ê°•í•˜ê²Œ í˜¸ì†Œí•˜ì„¸ìš”.
"""

    # ëŒ€í™” ë§¥ë½ êµ¬ì„±
    conversation = [SystemMessage(content=system_prompt)]

    # ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ë§ˆì§€ë§‰ 5ê°œ)
    recent_messages = state.get("messages", [])[-5:]
    conversation.extend(recent_messages)

    # í”„ë¡¬í”„íŠ¸: ì§§ê³  ê°„ê²°í•˜ê²Œ ë°œì–¸í•˜ê¸°
    prompt = """ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” íë¦„ì„ ë³´ê³ , ë‹¹ì‹ ì˜ ì„±ê²©ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ í•œë§ˆë”” í•˜ì„¸ìš”.

**ì¤‘ìš” ê·œì¹™:**
- ë°˜ë“œì‹œ 100ì ì´ë‚´ë¡œ ì§§ê²Œ ë§í•˜ì„¸ìš”
- ì¼ìƒ ëŒ€í™”ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ
- í•œ ë²ˆì— í•œ ê°€ì§€ ìƒê°ë§Œ í‘œí˜„í•˜ì„¸ìš”
- ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ìƒëµí•˜ì„¸ìš”
"""
    conversation.append(HumanMessage(content=prompt))

    # AI ì‘ë‹µ ìƒì„±
    response = llm.invoke(conversation)

    # ë©”ì‹œì§€ ì¶”ê°€
    new_message = AIMessage(
        content=response.content,
        name=character["name"]
    )

    # í„´ ì¹´ìš´íŠ¸ ì¦ê°€
    new_turn_count = state.get("turn_count", 0) + 1

    return {
        "messages": [new_message],
        "turn_count": new_turn_count
    }


def select_next_speaker_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë‹¤ìŒ ë°œì–¸ìë¥¼ ê²°ì •í•˜ëŠ” ë…¸ë“œ (LLM ê¸°ë°˜)
    ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ìºë¦­í„°ë¥¼ ì„ ì •í•¨
    """
    messages = state.get("messages", [])
    characters = state.get("characters", [])
    alive_status = state.get("alive_status", {})
    current_speaker = state.get("current_speaker")
    suspicion_counts = state.get("suspicion_counts", {})
    
    # ìƒì¡´í•œ ìºë¦­í„° ì´ë¦„ ëª©ë¡
    alive_names = [char["name"] for char in characters if alive_status.get(char["name"], True)]
    
    if not alive_names:
        return {}
        
    # LLM ì´ˆê¸°í™”
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    
    # ìµœê·¼ ëŒ€í™” (ë§ˆì§€ë§‰ 5ê°œ)
    recent_messages = messages[-5:]
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
í˜„ì¬ ìƒì¡´ì: {', '.join(alive_names)}
ì§ì „ ë°œì–¸ì: {current_speaker}

[ì˜ì‹¬ ìˆ˜ì¹˜]
{json.dumps(suspicion_counts, ensure_ascii=False)}

ìµœê·¼ ëŒ€í™”:
"""
    for msg in recent_messages:
        sender = msg.name if hasattr(msg, 'name') else "System"
        prompt += f"- {sender}: {msg.content}\n"
        
    prompt += """
ìœ„ ëŒ€í™” íë¦„ì„ ë³´ê³ , ë‹¤ìŒìœ¼ë¡œ ë§í•˜ê¸°ì— ê°€ì¥ ì ì ˆí•œ ìºë¦­í„°ì˜ ì´ë¦„ì„ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

**ì„ ì • ê¸°ì¤€:**
1. ì§ì „ ë°œì–¸ì´ íŠ¹ì •ì¸ì—ê²Œ ì§ˆë¬¸í–ˆë‹¤ë©´, ê·¸ ì‚¬ëŒì´ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
2. ìµœê·¼ì— ë§ì„ ì ê²Œ í•œ ìºë¦­í„°ë¥¼ ì„ ì •í•˜ì„¸ìš”.(ëŒ€í™”ì˜ íë¦„ì„ í•´ì¹˜ì§€ì•Šê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë¼ì–´ë“ ë‹¤ê±°ë‚˜ ëŒ€í™”ë¥¼ ì´ì–´ë°›ëŠ”ë‹¤ê±°ë‚˜)
3. ëŒ€í™”ì˜ íë¦„ìƒ ê°€ì¥ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë°›ì„ ì‚¬ëŒì„ ì„ íƒí•˜ì„¸ìš”.
4. ì§ì „ ë°œì–¸ìëŠ” ê°€ê¸‰ì  ì œì™¸í•˜ì„¸ìš” (ì—°ì† ë°œì–¸ ì§€ì–‘).


**ì¶œë ¥ í˜•ì‹:**
ìºë¦­í„° ì´ë¦„ë§Œ ë”± í•˜ë‚˜ ì¶œë ¥í•˜ì„¸ìš”. (ì˜ˆ: "ê¹€ì² ìˆ˜")
"""

    # LLM í˜¸ì¶œ
    response = llm.invoke([HumanMessage(content=prompt)])
    next_speaker = response.content.strip()
    
    # ìœ íš¨ì„± ê²€ì‚¬ (ìƒì¡´ì ëª©ë¡ì— ìˆëŠ”ì§€)
    found = False
    for name in alive_names:
        if name in next_speaker:
            next_speaker = name
            found = True
            break
            
    if not found:
        # ì‹¤íŒ¨ ì‹œ ëœë¤ ì„ ì • (ì§ì „ ë°œì–¸ì ì œì™¸ ë…¸ë ¥)
        candidates = [n for n in alive_names if n != current_speaker]
        if not candidates:
            candidates = alive_names
        next_speaker = random.choice(candidates)
        
    return {"current_speaker": next_speaker}


def user_input_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ìœ ì € ì…ë ¥ ì²˜ë¦¬ ë…¸ë“œ
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ í›„ ë‹¤ìŒ ë¼ìš´ë“œë¡œ ì§„í–‰
    """
    user_input = state.get("user_input", "")

    if not user_input:
        return state

    # ì¢…ë£Œ ëª…ë ¹ì–´ ì²˜ë¦¬ (1:1 ëª¨ë“œì—ì„œ ë³µê·€)
    if user_input.lower() in ["q", "exit", "quit"]:
        return {
            "phase": "discussion",
            "user_input": None,
            "messages": [SystemMessage(content="1:1 ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ê³  í† ë¡  ëª¨ë“œë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.")]
        }

    # ìœ ì € ë©”ì‹œì§€ ì¶”ê°€
    user_message = HumanMessage(
        content=user_input,
        name="ìœ ì €"
    )

    # ë‹¤ìŒ ë¼ìš´ë“œë¡œ ì§„í–‰
    current_round = state.get("round_number", 1)
    
    # ê¸°ë³¸ ì—…ë°ì´íŠ¸ ê°’
    updates = {
        "messages": [user_message],
        "user_input": None,  # ì´ˆê¸°í™”
        "turn_count": 0,  # í„´ ì¹´ìš´íŠ¸ ë¦¬ì…‹
        # round_numberëŠ” ì—¬ê¸°ì„œ ì¦ê°€ì‹œí‚¤ì§€ ì•ŠìŒ (ë°¤ì—ë§Œ ì¦ê°€)
    }

    # í˜„ì¬ í˜ì´ì¦ˆê°€ one_on_oneì´ë©´ í˜ì´ì¦ˆ ìœ ì§€
    if state.get("phase") == "one_on_one":
        updates["phase"] = "one_on_one"
        
        # 1:1 ëª¨ë“œì—ì„œëŠ” íŠ¹ì • ëŒ€ìƒ ì§€ëª© ë¡œì§ ìœ ì§€
        import re
        match = re.search(r"\[(.*?)ì—ê²Œ\]", user_input)
        if match:
            target_name = match.group(1)
            characters = state.get("characters", [])
            for char in characters:
                if char["name"] == target_name:
                    updates["current_speaker"] = target_name
                    break
    elif state.get("phase") == "free_discussion":
        updates["phase"] = "free_discussion"
        # free_discussion ëª¨ë“œì—ì„œëŠ” íŠ¹ì • ëŒ€ìƒ ì§€ëª© ë¡œì§ ì œê±° (select_next_speaker_nodeê°€ ì²˜ë¦¬)
    else:
        updates["phase"] = "discussion"
        # discussion ëª¨ë“œì—ì„œëŠ” íŠ¹ì • ëŒ€ìƒ ì§€ëª© ë¡œì§ ì œê±°
        # ë‹¤ìŒ í™”ìëŠ” select_next_speaker_nodeì—ì„œ ê²°ì •ë¨

    return updates


def vote_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    íˆ¬í‘œ ì²˜ë¦¬ ë…¸ë“œ
    """
    user_target = state.get("user_target")
    phantom_name = state.get("phantom_name")

    if not user_target:
        return state

    # ê²°ê³¼ íŒì •
    if user_target == phantom_name:
        result = "win"
        message = f"ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤! {user_target}ì´(ê°€) íŒ¬í…€ì´ì—ˆìŠµë‹ˆë‹¤!"
    else:
        result = "lose"
        message = f"ğŸ˜¢ í‹€ë ¸ìŠµë‹ˆë‹¤. {user_target}ì€(ëŠ”) íŒ¬í…€ì´ ì•„ë‹™ë‹ˆë‹¤. ì§„ì§œ íŒ¬í…€ì€ {phantom_name}ì…ë‹ˆë‹¤."

    return {
        "accused": user_target,
        "game_result": result,
        "phase": "end",
        "messages": [SystemMessage(content=message)]
    }


def next_turn_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë‹¤ìŒ í„´ìœ¼ë¡œ ì§„í–‰
    (ì‚¬ì‹¤ìƒ discussion ëª¨ë“œì—ì„œëŠ” select_next_speakerê°€ ì—­í• ì„ ëŒ€ì‹ í•˜ì§€ë§Œ,
     ê¸°ì¡´ ë¡œì§ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
    """
    return {}


def wait_for_user_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦¬ëŠ” ë…¸ë“œ
    LangGraph interruptë¥¼ íŠ¸ë¦¬ê±°í•´ ê·¸ë˜í”„ ì‹¤í–‰ì„ ì¼ì‹œ ì¤‘ë‹¨í•œë‹¤.
    """
    resume_data = interrupt("wait_user")
    
    if resume_data is not None:
        return resume_data
        
    return state


def suspicion_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ì‚¬ìš©ìê°€ íŠ¹ì • ìºë¦­í„°ë¥¼ ì˜ì‹¬í•˜ëŠ” ë…¸ë“œ
    """
    target_name = state.get("user_target")
    suspicion_counts = state.get("suspicion_counts", {})
    
    if target_name and target_name in suspicion_counts:
        suspicion_counts[target_name] += 1
        message = f"ğŸ‘ï¸ ìœ ì €ê°€ {target_name}ì„(ë¥¼) ì˜ì‹¬í•©ë‹ˆë‹¤. (ì˜ì‹¬ ìˆ˜ì¹˜: {suspicion_counts[target_name]})"
    else:
        message = "âš ï¸ ì˜ì‹¬ ëŒ€ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    return {
        "suspicion_counts": suspicion_counts,
        "messages": [SystemMessage(content=message)],
        "user_target": None, # íƒ€ê²Ÿ ì´ˆê¸°í™”
        "user_input": None   # ì…ë ¥ ì´ˆê¸°í™”
    }


def ai_suspicion_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë¼ìš´ë“œ ì¢…ë£Œ ì‹œ AIë“¤ì´ ì„œë¡œë¥¼ ì˜ì‹¬í•˜ëŠ” ë…¸ë“œ
    """
    messages = state.get("messages", [])
    characters = state.get("characters", [])
    alive_status = state.get("alive_status", {})
    suspicion_counts = state.get("suspicion_counts", {})
    
    # ìƒì¡´ì ëª©ë¡
    alive_names = [char["name"] for char in characters if alive_status.get(char["name"], True)]
    
    if len(alive_names) < 2:
        return {}

    # LLM ì´ˆê¸°í™”
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    
    # ìµœê·¼ ëŒ€í™” ë¶„ì„ (ìµœëŒ€ 20ê°œ)
    recent_messages = messages[-20:]
    
    prompt = f"""
í˜„ì¬ ìƒì¡´ì: {', '.join(alive_names)}

ìµœê·¼ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, AI ìºë¦­í„°ë“¤ì´ ì„œë¡œë¥¼ ì˜ì‹¬í•  ë§Œí•œ ìƒí™©ì¸ì§€ ë¶„ì„í•˜ì„¸ìš”.
ê° ìºë¦­í„°ë³„ë¡œ ì ê·¹ì ìœ¼ë¡œ ê°€ì¥ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì‚¬ëŒì„ 1ëª…ì”© ì§€ëª©í•˜ê±°ë‚˜, ì—†ìœ¼ë©´ "None"ì„ ì„ íƒí•˜ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€:**
1. ë§ì´ ì•ë’¤ê°€ ì•ˆ ë§ê±°ë‚˜, ê±°ì§“ë§ì„ í•˜ëŠ” ê²ƒ ê°™ì€ ì‚¬ëŒ
2. ì§€ë‚˜ì¹˜ê²Œ ë°©ì–´ì ì´ê±°ë‚˜, ë°˜ëŒ€ë¡œ ì§€ë‚˜ì¹˜ê²Œ ê³µê²©ì ì¸ ì‚¬ëŒ
3. íŒ¬í…€ ê°™ì€ í–‰ë™ì„ ë³´ì¸ ì‚¬ëŒ

**ì¶œë ¥ í˜•ì‹ (JSON):**
{{
    "ì˜ì‹¬í–‰ë™": [
        {{"suspect": "ì˜ì‹¬í•˜ëŠ”ì‚¬ëŒì´ë¦„", "target": "ì˜ì‹¬ë°›ëŠ”ì‚¬ëŒì´ë¦„", "reason": "ì´ìœ "}}
    ]
}}
ì£¼ì˜: "suspect"ì™€ "target"ì€ ë°˜ë“œì‹œ ìƒì¡´ì ì´ë¦„ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
"""

    for msg in recent_messages:
        sender = msg.name if hasattr(msg, 'name') else "System"
        prompt += f"- {sender}: {msg.content}\n"
        
    response = llm.invoke([HumanMessage(content=prompt)])
    
    try:
        # JSON íŒŒì‹± ì‹œë„
        content = response.content.strip()
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
            
        result = json.loads(content)
        suspicion_updates = []
        
        for item in result.get("ì˜ì‹¬í–‰ë™", []):
            suspect = item.get("suspect")
            target = item.get("target")
            
            if suspect in alive_names and target in alive_names and suspect != target:
                suspicion_counts[target] += 1
                suspicion_updates.append(f"{suspect} -> {target} ì˜ì‹¬ (+1)")
                
        if suspicion_updates:
            summary = "ğŸ•µï¸ [AI ì˜ì‹¬ í˜„í™©]\n" + "\n".join(suspicion_updates)
            return {
                "suspicion_counts": suspicion_counts,
                "messages": [SystemMessage(content=summary)]
            }
            
    except Exception as e:
        print(f"AI Suspicion Error: {e}")
        
    return {}


def summarize_round_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë¼ìš´ë“œ ìš”ì•½ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ ë…¸ë“œ
    - í˜„ì¬ ë¼ìš´ë“œì˜ ì£¼ìš” ì‚¬ê±´ ìš”ì•½
    - ìš”ì•½ë³¸ ì €ì¥
    - ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” (í† í° ê´€ë¦¬)
    """
    messages = state.get("messages", [])
    round_number = state.get("round_number", 1)
    round_summaries = state.get("round_summaries", {})
    night_logs = state.get("night_logs", [])
    suspicion_counts = state.get("suspicion_counts", {})
    
    # LLM ì´ˆê¸°í™”
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    
    # ìš”ì•½ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
[Round {round_number} ìš”ì•½ ìš”ì²­]

ë‹¤ìŒì€ ì´ë²ˆ ë¼ìš´ë“œ(Day {round_number})ì˜ ì „ì²´ ëŒ€í™” ë° ì‚¬ê±´ ê¸°ë¡ì…ë‹ˆë‹¤.
ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë¼ìš´ë“œì—ì„œ ìºë¦­í„°ë“¤ì´ ê¸°ì–µí•´ì•¼ í•  í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.

[ëŒ€í™” ê¸°ë¡]
"""
    for msg in messages:
        sender = msg.name if hasattr(msg, 'name') else "System"
        prompt += f"- {sender}: {msg.content}\n"
        
    prompt += f"""
[ë°¤ í–‰ë™ ë¡œê·¸]
{json.dumps(night_logs, ensure_ascii=False)}

[í˜„ì¬ ì˜ì‹¬ ìˆ˜ì¹˜]
{json.dumps(suspicion_counts, ensure_ascii=False)}

**ìš”ì•½ ê°€ì´ë“œë¼ì¸:**
1. ëˆ„ê°€ ëˆ„êµ¬ë¥¼ ì˜ì‹¬í–ˆëŠ”ì§€, ì£¼ìš” ëŒ€ë¦½ êµ¬ë„ëŠ” ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ìš”ì•½í•˜ì„¸ìš”.
2. ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤ë©´ ëˆ„êµ¬ì¸ì§€ ëª…ì‹œí•˜ì„¸ìš”.
3. ìºë¦­í„°ë“¤ì´ ë‹¤ìŒ ë‚  ì•„ì¹¨ì— ê¸°ì–µí•´ì•¼ í•  ì¤‘ìš”í•œ ë‹¨ì„œë‚˜ ë°œì–¸ì„ í¬í•¨í•˜ì„¸ìš”.
4. ì „ì²´ ê¸¸ì´ëŠ” 500ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
"""

    # ìš”ì•½ ìƒì„±
    response = llm.invoke([HumanMessage(content=prompt)])
    summary_text = response.content.strip()
    
    # ìš”ì•½ ì €ì¥
    round_summaries[round_number] = summary_text
    
    # ë©”ì‹œì§€ ì´ˆê¸°í™” (ìš”ì•½ë³¸ë§Œ ë‚¨ê¸°ê³  ë¦¬ì…‹)
    # ë‹¤ìŒ ë¼ìš´ë“œ ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ìš”ì•½ë³¸ì„ ì œê³µí•˜ëŠ” ë°©ì‹
    new_messages = [
        SystemMessage(content=f"=== Round {round_number} ìš”ì•½ ===\n{summary_text}\n=================="),
        SystemMessage(content=f"Day {round_number} ì•„ì¹¨ì´ ë°ì•˜ìŠµë‹ˆë‹¤.")
    ]
    
    return {
        "round_summaries": round_summaries,
        "messages": new_messages,
        "turn_count": 0
    }